{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "from __future__ import division\n",
    "\n",
    "#Please complete the following Naive Bayes code based on the given instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Please handle the data with 'dataframe' type, remember to print/display the test and training datasets\n",
    "train = #define\n",
    "test = #define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groundtruth = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a Gaussian function to estimate the probability of a given attribute value, given the known mean and standard deviation for the attribute estimated from the training data.\n",
    "Knowing that the attribute summaries where prepared for each attribute and class value, the result is the conditional probability of a the attribute value given a class value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcConditionalProb(testset,df_temp):\n",
    "    '''\n",
    "    This function takes the test dataset and a dataframe given one class label.\n",
    "    The function returns the conditional probability given a column(feature).\n",
    "    '''\n",
    "    #hint: you can test.ix[:,i]\n",
    "    prob = 1.0\n",
    "    ###\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow intructions for the given code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame()\n",
    "#define a variable probTarget which is equal to the probablity of a given class.(upto 4 decimal places)\n",
    "test = test.drop('target', axis = 1)\n",
    "probTarget = #define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each label in the training dataset, we compute the probability of the test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label in train['target'].unique():\n",
    "    df_temp = train[train['target']==label]\n",
    "    df_temp = df_temp.drop('target', axis = 1)\n",
    "    testset = test.copy(deep=True)\n",
    "    prob_df[label] = (probTarget)*calcConditionalProb(testset, df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list 'prediction' that stores the label of the class with highest probability for each test instance which are stored in prob_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = #define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy of your model. The function should take the prediction and groundTruth as inputs and return the \n",
    "confusion matrix. The confusion matrix is of 'dataframe' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(prediction, groundTruth):\n",
    "    '''\n",
    "    Return and print the confusion matrix.\n",
    "    '''\n",
    "    return confMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the confusionMatrix function and print the confusion matrix as well as the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groundTruth = ##\n",
    "prediction = ##\n",
    "conf = confusionMatrix(prediction, groundTruth)\n",
    "accuracy = #define accuracy\n",
    "print 'Accuracy = '+str(accuracy)+'%'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
