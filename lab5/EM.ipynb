{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.219751</td>\n",
       "      <td>1.151636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.409724</td>\n",
       "      <td>5.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.091534</td>\n",
       "      <td>7.432705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.731577</td>\n",
       "      <td>0.909840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988678</td>\n",
       "      <td>6.979712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0 -0.219751  1.151636\n",
       "1  1.409724  5.004789\n",
       "2 -1.091534  7.432705\n",
       "3 -2.731577  0.909840\n",
       "4  0.988678  6.979712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sys import maxint\n",
    "\n",
    "#Please complete the following Expectation Maximization code, implementing a batch EM is sufficient for this lab\n",
    "\n",
    "#set a random seed, remember to set the correct seed if you want to use another command for seeding\n",
    "rand.seed(124)\n",
    "\n",
    "# we have *two* clusters. Note that the covariance matrices are diagonal\n",
    "mu = [0, 6]\n",
    "sig = [ [3, 0], [0, 4] ]\n",
    "\n",
    "muPrime = [6, 0]\n",
    "sigPrime = [ [5, 0], [0, 2] ]\n",
    "\n",
    "\n",
    "#Generate samples of type MVN and size 100 using mu/sigma and muPrime/sigmaPrime. \n",
    "x1, y1 = #MVN sample of size 100 using mu and sigma\n",
    "x2, y2 = #MVN sample of size 100 using muPrime and sigmaPrime\n",
    "\n",
    "\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "#Convert the data which now includes 'x' and 'y' to a dataframe. \n",
    "data = {'x': x, 'y': y}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "# Load the data and inspect it\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial guess for mu, sigma, and alpha which are initially bad, α = probability of class asignment. ∑α=1 for k=1 to K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initialGuess = { 'mu': [2,2], 'sig': [ [1, 0], [0, 1] ], 'muPrime': [5,5], 'sigPrime': [ [1, 0], [0, 1] ], 'alpha': [0.4, 0.6]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the posterior with the help of computing the pdf, e.g. using norm.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior(val, mu, sig, alpha):\n",
    " '''posteriors'''\n",
    "  return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The E-step, estimate w, this w is the \"soft guess\" step for the class labels. You have to use the already defined posteriors in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expectation(dataFrame, parameters):\n",
    "  '''This function uses the posterios to estimate w.'''\n",
    "  return #dataframe with the soft guess for the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The M - step: update estimates of alpha, mu, and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximization(dataFrame, parameters):\n",
    "  '''Update parameters'''\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Convergence, define your convergence criterion. You can define a new function for this purpose or just check it in the loop. You will have to use this function at the end of each while/for loop's EM iteration to check whether we have reached \"convergence\" or not. So to test for convergence, we can calculate the log likelihood at the end of each EM step (e.g. model fit with these parameters) and then test whether it has changed “significantly” (defined by the user, e.g. it should be something similar to: if(loglik.diff < 1e-6) ) from the last EM step. If it has, then we repeat another step of EM. If not, then we consider that EM has converged and then these are our final parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate until convergence: with E-step, M-step, checking our etimates of mu/checking whether we have reached convergece, and updating the parameters for the next iteration. This part of the code should print a figure for *each* iteration, the *final* parameters, and #iterations. The final outcome that you have to submit is your EM code and a .pdf report. Your report should have the plots for **each** iteration, your **explanation on the convergence criterion you used based on last paragraph's explanations**, your final parameters, and the general flow of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop until the parameters converge\n",
    "\n",
    "iters = 0\n",
    "params = pd.DataFrame(initialGuess)\n",
    "\n",
    "while ###:\n",
    "  iters += 1\n",
    "  # E-step\n",
    " \n",
    "  # M-step\n",
    " \n",
    "  # see if our estimates of mu have changed and check convergence\n",
    "  \n",
    "  #print parameters for each iteration\n",
    "\n",
    "  # update labels and parameters for the next iteration\n",
    "   \n",
    "  # return a scatter plot for each iteration, e.g. plt.scatter(df_new['x'], df_new['y'], ...) while the colors are based on the labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
